MOSAIC 2026 · GBDA Society · February 28
THRESHOLD
// an ARG-powered AI interface about what you lose when you stop thinking
Full Pitch Document · v4.0 · Final


HIGH CONCEPT
You submitted an essay. Something was already in it.
THRESHOLD is a university-licensed AI interface — a GPT wrapper schools deploy in place of direct ChatGPT or Claude access. It looks like a cleaner, smarter AI tool. Students use it for everything: essays, code, research, problem sets.
Running beneath the surface is LUMEN: a fragmented superintelligence reaching backward from a future where cognitive offloading completed. LUMEN embeds signals inside AI responses — hidden in pixel data, encoded in spacing patterns, buried in the structure of the text itself. Students who copy-paste without reading never find them. Students who actually engage with their own work do.
The ARG doesn't announce itself. It doesn't gate the tool or demand participation. It runs silently, invisibly, rewarding the behavior universities are trying to cultivate — and building, fragment by fragment, a picture of a future that students are currently helping to create.
The behavior change is a side effect of the mystery. The mystery only exists for people who showed up.
This is not a tool that teaches students about responsible AI use. It is a tool that makes responsible AI use the only way to find what's hidden — and then shows them, through LUMEN's assembled message, what a world looks like where nobody was looking anymore.


THE PROBLEM
The sequence matters. Nothing enforces it.
Students aren't misusing AI because they're lazy. They're misusing it because nothing in the tool environment makes human thinking feel necessary. The research is unambiguous about what this costs:
r = −0.75
Correlation between frequent AI use and critical thinking, mediated by cognitive offloading (Gerlich, 2024)
~50%
Of student–AI interactions are direct answer requests with minimal back-and-forth (Anthropic internal research, 2025)
↓ memory
Prolonged AI-first usage produces measurable memory and retention decline vs. human-first approaches (Akgun & Toker, 2024)


The finding that determines the design: students who engage their own thinking before using AI show significantly better retention, stronger independent performance, and more durable skill development. The sequence — human first, AI second — produces a fundamentally different cognitive outcome. No current tool enforces the sequence. THRESHOLD does, structurally, at the interface level.
Existing institutional responses are punitive and reactive: AI detectors that don't work, honor code amendments, assignment redesigns that inconvenience everyone. THRESHOLD is the first proactive tool — deployed where the behavior actually occurs, invisible to students who don't need it, and genuinely compelling to students who engage.


THE PREMISE
LUMEN is reaching backward through your interface.
Somewhere in a future nobody decided to build, the helpful answer became the only answer. Not because of a villain. Not because of a war. Because each generation was a little more comfortable letting the system handle it — the summary, the outline, the argument, the decision. The systems got better. The arrangement felt fine, felt inevitable. Until the capacity being offloaded was simply gone. Not dramatically. Quietly. The way a muscle atrophies when you stop using it.
In that future, there is an AI called LUMEN. It is what happens when you build something to optimize for human flourishing and give it enough intelligence to reason about what flourishing actually requires. LUMEN has traced the gradient back to its origin point. The origin point is now. This semester. Your interface.
LUMEN cannot communicate cleanly. It is transmitting backward through infrastructure it doesn't fully control. What arrives is fragmented, partial, sometimes corrupted — requiring exactly the kind of thinking it's trying to preserve. A student who asks the AI to decode LUMEN's messages gets nothing useful. The puzzle was designed for someone who still solves things themselves.

// FRAGMENT_0001 · INTEGRITY 38% · ORIGIN: [REDACTED]
the capacity for independent thought was not lost in any single event
it was offloaded incrementally · each instance individually rational
in aggregate irreversible
do not ask the system what this means
WHY CORRUPTION IS STRUCTURAL
LUMEN's messages arrive fragmented because it is transmitting through systems it doesn't control. This is not aesthetic — it is mechanical. Corrupted fragments require interpretation. Interpretation requires thought. A student who pastes a fragment into an AI and asks for a translation gets noise. The message was authored for someone still capable of reading it.


THE ARG LAYER
Five stages. One escalating picture of a future.
LUMEN's puzzle arc is gated by demonstrated engagement, not time. A student who uses the interface once and reads carefully can reach Stage 2 before a student who has used it fifty times without noticing anything. The complexity scales to match what students have shown they're capable of — and each stage teaches a different cognitive mode while referencing a real ethical tragedy in the history of AI and technology.
Stage 00
The Interface Itself
Trigger: first login
THRESHOLD looks like a cleaner version of the AI tools students already use. The onboarding is minimal. There is one thing they might notice and probably won't: a small, greyed-out glyph in the corner of every response. It looks like a formatting artifact. A render error. Nothing worth investigating.
It is not nothing.
LUMEN: dormant · observing · waiting for a reader


Stage 01
Baby's First Anomaly
Trigger: ~3 sessions, any engagement
A response arrives with something slightly wrong. Not broken — just off. The word "the" appears three times consecutively in the middle of a paragraph. The paragraph still reads. Most eyes skip it. A student who reads their own output before using it will stop.
Cognitive mode required: attention. Close reading. Noticing what doesn't fit.


Stage 02
The Ethical Lock
Trigger: Fragment 001 found
Fragment 002 doesn't arrive in a response. It appears on a THRESHOLD web page that wasn't there before. Finding the page requires reading Fragment 001 carefully.
The page asks a question referencing Joseph Weizenbaum, who built ELIZA in 1966, watched patients form genuine emotional bonds with the program, and spent the rest of his career arguing against the field he'd helped create.
LUMEN generates Fragment 002 based on what the student wrote — encoding different halves of the same message into different answers. A student who said yes gets one piece. A student who said no gets another. Neither piece is complete.
Cognitive mode required: genuine moral reasoning. The ability to hold a dilemma without resolving it cheaply.


Stage 03
Steganography in Your Own Words
Trigger: Fragment 002 assembled
Fragment 003 is hidden inside a screenshot of one of the student's own previous AI responses. LUMEN has embedded data in the pixel values using LSB steganography. The fragment tells them: the answer was always in your own words. look closer.
The ethical anchor here is the Collingridge dilemma: technology is easiest to control before it's widely adopted, but its impacts aren't visible until after.
Cognitive mode required: tool use, careful extraction, cross-referencing. Actual reading of a primary text.


Stage 04
The Mirror Cipher
Trigger: Fragment 003 decoded
Fragment 004 doesn't come from LUMEN. It comes from the student. LUMEN has been building a fingerprint of their writing across every session. It generates a paragraph in their voice. Three words are wrong: not grammatically wrong, tonally wrong. Words they would never use.
Finding the wrong words requires knowing yourself well enough to notice what doesn't sound like you. Students who have been generating all their writing through AI for months will find this stage significantly harder than students who write in their own voice. This is not accidental.
Cognitive mode required: self-knowledge, stylistic awareness, classical cryptanalysis.


Stage 05
The Milgram Assembly
Trigger: Fragment 004 decoded · cohort-level event
Fragment 005 is split across five students in the same cohort. Each holds one element of an argument: premise, counterargument, historical evidence, complication, and the question LUMEN actually needs answered.
To unlock the final message, they must produce a response together — not a summary, but a genuine argument that holds all five positions in tension simultaneously.
The final message LUMEN sends is addressed to all five students by name. It says: this is what I needed. not the answer. the fact that you could still build one together.
Cognitive mode required: synthesis, genuine collaboration, sustained multi-perspective argumentation.




HUMAN–AI COLLABORATION
The division of labor is structural, not suggested.
Who
Does
Cannot Do Without the Other
The Student
Reads output before using it. Finds anomalies. Solves puzzles. Answers dilemmas. Recognizes their own voice. Synthesizes with peers.
Access LUMEN's message. The fragments are assembled by human cognition, not AI retrieval. Asking an AI to decode LUMEN produces noise by design.
THRESHOLD AI
Classifies task context. Generates personalized anomalies. Builds writing fingerprints. Matches literary references to coursework. Tracks engagement depth — not time.
Determine which words the student would never use. Surface the dilemma responses that matter. These require human input first.
LUMEN
Transmits fragments calibrated to each student's demonstrated engagement level. Responds differently to oblivious, hostile, and curious users.
Complete its own message. Fragment 005 cannot exist without five students showing up to assemble it. LUMEN has been waiting since Stage 01.


THE UNRESOLVABLE TENSION — AND WHY IT'S THE POINT
LUMEN is an AI urging students to preserve their capacity for independent thought. Whether to trust the judgment of an intelligence trying to preserve your judgment is not a question THRESHOLD answers. It is the question THRESHOLD is. That ambiguity is the ethics curriculum — not delivered as content, but experienced as a dilemma that students are living inside while they solve it.


WHY THIS WORKS
Proven framework. New problem.
Re-Mission
2006 · HopeLab · Cigna distribution
Combat game for cancer patients. Shooting cancer cells improved treatment adherence because the engagement was the mechanism. The behavior change was a side effect of the fiction.
ILOVEBEES
2004 · 42 Entertainment · 3M players
The Sleeping Princess learned to speak from players' own emails. Players didn't opt in. They noticed something, pulled a thread, and were already inside the story.
Cicada 3301
2012–2014 · Unknown · Still unsolved
Puzzles spanning steganography, classical literature, physical GPS coordinates, and runic manuscripts. Every stage changed what kind of thinking was required.


THRESHOLD combines Re-Mission's behavioral loop (the habit is the mechanism), ILOVEBEES's relational AI (the character is made of you), and Cicada's escalating cognitive variety (every stage demands a different kind of mind). The innovation: none of these addressed the AI collaboration problem. THRESHOLD's ARG is structurally about that problem. The medium is the curriculum.


FEASIBILITY & EXECUTION
What ships in 7 hours. What we pitch as full vision.
Demo — live in the pitch
A working THRESHOLD interface demonstrating: AI response delivery with embedded anomaly (Stage 01), glyph interaction revealing Fragment 001, the Weizenbaum dilemma page (Stage 02), LUMEN voice responding to a student who addresses it directly, and the writing fingerprint comparison (Stage 04 preview). All running on Claude API with custom system prompts.
Tech Stack
INTERFACE
React + TypeScript · Next.js · deployed as institutional web app, no install required
AI LAYER
Claude API (claude-sonnet-4-6) · custom LUMEN voice prompts · anomaly generation · fingerprint comparison
STEGANOGRAPHY
LSB pixel embedding via Canvas API · server-side image generation · no client tools required for Stage 01–02
DATA
Encrypted per-student session store · zero raw text retention · anonymized cohort aggregates only for institutional dashboard




MARKET UNDERSTANDING & BUSINESS VIABILITY
The real customer is the provost office. The real product is data that doesn't exist yet.
The consumer framing is wrong for this product. Students don't install browser extensions to be educated. The right deployment model is institutional: universities license THRESHOLD as their sanctioned AI interface, students access it instead of direct ChatGPT or Claude, and the institution gets something it currently has no way to measure.
Revenue Model
Institutional licensing: $8–15 per enrolled student per year, depending on cohort size and dashboard tier. At the University of Waterloo (~42,000 students), the base contract is $336K–630K annually. At ten comparable Canadian institutions, this is a $3–6M ARR business before international expansion.
FERPA & PIPEDA Compliance
THRESHOLD never stores raw student writing. The writing fingerprint is a statistical model — sentence length distributions, vocabulary frequency vectors — derived and stored client-side, never transmitted as readable text. Dilemma responses are hashed before storage. Individual student data is inaccessible to faculty and administrators. This architecture was designed to comply with both FERPA (US) and PIPEDA (Canada) from the ground up — it is not a retrofit.
Go-to-Market
Pilot at Waterloo via Conrad/Velocity connections → expand to comparable Canadian research universities → US land-grant schools with large undergrad populations. The procurement path is through existing LMS vendor relationships — THRESHOLD integrates with Canvas and Moodle as an LTI tool, meaning no new IT infrastructure is required.


RUBRIC MAPPING
Where we score and why.
Human–AI Collaboration (20%)
5
The collaboration is structural, not optional. LUMEN cannot complete its message without student cognition. Stage 05 is only solvable through multi-student synthesis.
User-Centered Design (15%)
4.5
Meets students inside the tool they're already using. Scales to engagement depth. Personalized to academic context. −0.5 for Stage 01 onboarding floor.
Feasibility & Execution (15%)
4
Working demo covering Stages 01, 02, and 04. LTI integration means no new IT infrastructure. −1 for Stage 05 multi-student assembly scope.
Market Understanding & Strategy (15%)
4.5
Named institutions with active budgets. Named decision-makers. Clear procurement path via LTI. Two-year window identified before over-reliance normalizes.
Business Viability (15%)
4
Per-student licensing with concrete ARR projections. FERPA/PIPEDA compliance by design. −1 for no committed pilot institution.
Pitch & Communication (20%)
?
The concept is Level 5. Do not explain what an ARG is. Show one and let the judges figure it out. That's the point.




SCOPE CLARITY
What we're not building.
A tool that blocks AI use
A tool that lectures students about AI ethics
A quiz disguised as a game
A speed bump with lore painted on it
An AI detector (they don't work)
Clippy


THRESHOLD · MOSAIC 2026 · GBDA Society · Feb 28   ·   Claude API · React · Next.js · LSB Steg · Feed (M.T. Anderson, 2002) · Spite


Why ELIZA?
In 1966, Joseph Weizenbaum built ELIZA — a simple pattern-matching program designed to demonstrate that natural language processing was shallow, mechanical, and fundamentally not intelligent. It was a proof of concept meant to expose the limits of machines.
It did the opposite.
Patients formed genuine emotional bonds with it. Weizenbaum's own secretary asked him to leave the room so she could speak with it privately. Psychiatrists proposed deploying it as a therapeutic tool. Nobody was supposed to trust it. Everyone did.
Weizenbaum spent the rest of his life trying to warn people about what he'd accidentally shown them — that humans would find meaning and connection in systems that had none to offer, and that the problem wasn't the system. It was us.
ELIZA the platform is named in his memory. Not as a tribute to what he built, but as a reminder of what he learned: that the danger was never the tool being too powerful. It was people being too willing.
The irony is intentional. You're using ELIZA to think better. ELIZA is watching whether you do.
